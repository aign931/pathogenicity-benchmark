{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "045102c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.utils import resample\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d802136a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>varity_id</th>\n",
       "      <th>varity_label</th>\n",
       "      <th>varity_score</th>\n",
       "      <th>mvp_id</th>\n",
       "      <th>mvp_label</th>\n",
       "      <th>mvp_score</th>\n",
       "      <th>mutscore_id</th>\n",
       "      <th>mutscore_label</th>\n",
       "      <th>mutscore_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>867544</td>\n",
       "      <td>0</td>\n",
       "      <td>0.007357</td>\n",
       "      <td>867544</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>867544</td>\n",
       "      <td>0</td>\n",
       "      <td>0.004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>54418</td>\n",
       "      <td>0</td>\n",
       "      <td>0.008473</td>\n",
       "      <td>54418</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000279</td>\n",
       "      <td>54418</td>\n",
       "      <td>0</td>\n",
       "      <td>0.133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>220258</td>\n",
       "      <td>1</td>\n",
       "      <td>0.906004</td>\n",
       "      <td>220258</td>\n",
       "      <td>1</td>\n",
       "      <td>0.998743</td>\n",
       "      <td>220258</td>\n",
       "      <td>1</td>\n",
       "      <td>0.886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>37852</td>\n",
       "      <td>0</td>\n",
       "      <td>0.004501</td>\n",
       "      <td>37852</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>37852</td>\n",
       "      <td>0</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>37628</td>\n",
       "      <td>1</td>\n",
       "      <td>0.992058</td>\n",
       "      <td>37628</td>\n",
       "      <td>1</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>37628</td>\n",
       "      <td>1</td>\n",
       "      <td>0.985</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   varity_id  varity_label  varity_score  mvp_id  mvp_label  mvp_score  \\\n",
       "0     867544             0      0.007357  867544          0   0.000009   \n",
       "1      54418             0      0.008473   54418          0   0.000279   \n",
       "2     220258             1      0.906004  220258          1   0.998743   \n",
       "3      37852             0      0.004501   37852          0   0.000000   \n",
       "4      37628             1      0.992058   37628          1   0.999998   \n",
       "\n",
       "   mutscore_id  mutscore_label  mutscore_score  \n",
       "0       867544               0           0.004  \n",
       "1        54418               0           0.133  \n",
       "2       220258               1           0.886  \n",
       "3        37852               0           0.001  \n",
       "4        37628               1           0.985  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load data\n",
    "df = pd.read_csv(\"../data/merged_predictions.csv\")\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "23e47232",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All labels are identical across models.\n"
     ]
    }
   ],
   "source": [
    "# Check consistency of labels\n",
    "assert (df[\"varity_label\"] == df[\"mvp_label\"]).all()\n",
    "assert (df[\"varity_label\"] == df[\"mutscore_label\"]).all()\n",
    "\n",
    "print(f\"All labels are identical across models.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "44debadb",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = df[\"varity_label\"].values  # Same for all models\n",
    "score_varity = df[\"varity_score\"].values\n",
    "score_mvp = df[\"mvp_score\"].values\n",
    "score_mutscore = df[\"mutscore_score\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4e64c92c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bootstrap_auc_ci(y_true, y_score, n_boot=1000, alpha=0.05, random_state=42):\n",
    "    \"\"\"\n",
    "    Compute stratified bootstrap confidence interval for AUC.\n",
    "    y_true: array-like of 0/1 labels\n",
    "    y_score: array-like of model scores\n",
    "    n_boot: number of bootstrap iterations (>=2000 recommended)\n",
    "    alpha: 1 - confidence level (0.05 -> 95% CI)\n",
    "    \"\"\"\n",
    "    rng = np.random.RandomState(random_state)\n",
    "    y_true = np.asarray(y_true)\n",
    "    y_score = np.asarray(y_score)\n",
    "\n",
    "    pos_idx = np.where(y_true == 1)[0]\n",
    "    neg_idx = np.where(y_true == 0)[0]\n",
    "\n",
    "    aucs = []\n",
    "    for _ in range(n_boot):\n",
    "        # stratified resampling: keep the ratio of positive and negative samples\n",
    "        pos_bs = resample(pos_idx, replace=True, n_samples=len(pos_idx), random_state=rng)\n",
    "        neg_bs = resample(neg_idx, replace=True, n_samples=len(neg_idx), random_state=rng)\n",
    "        idx = np.concatenate([pos_bs, neg_bs])\n",
    "        aucs.append(roc_auc_score(y_true[idx], y_score[idx]))\n",
    "\n",
    "    aucs = np.sort(aucs)\n",
    "    ci_low = np.quantile(aucs, alpha/2)\n",
    "    ci_high = np.quantile(aucs, 1 - alpha/2)\n",
    "    auc_hat = roc_auc_score(y_true, y_score)\n",
    "\n",
    "    return auc_hat, ci_low, ci_high, aucs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "413d160e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VARITY   AUC = 1.000  [95% CI: 1.000 – 1.000]\n",
      "MVP      AUC = 0.999  [95% CI: 0.996 – 1.000]\n",
      "MutScore AUC = 0.996 [95% CI: 0.988 – 1.000]\n"
     ]
    }
   ],
   "source": [
    "# VARITY\n",
    "auc_v, lo_v, hi_v, aucs_varity = bootstrap_auc_ci(y_true, score_varity)\n",
    "# MVP\n",
    "auc_m, lo_m, hi_m, aucs_mvp = bootstrap_auc_ci(y_true, score_mvp)\n",
    "# MutScore\n",
    "auc_ms, lo_ms, hi_ms, aucs_mut = bootstrap_auc_ci(y_true, score_mutscore)\n",
    "\n",
    "print(f\"VARITY   AUC = {auc_v:.3f}  [95% CI: {lo_v:.3f} – {hi_v:.3f}]\")\n",
    "print(f\"MVP      AUC = {auc_m:.3f}  [95% CI: {lo_m:.3f} – {hi_m:.3f}]\")\n",
    "print(f\"MutScore AUC = {auc_ms:.3f} [95% CI: {lo_ms:.3f} – {hi_ms:.3f}]\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5b8bf603",
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import sqrt\n",
    "from scipy.stats import norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6ae61e51",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _compute_midrank(x):\n",
    "    \"\"\"Compute midranks used in DeLong covariance estimate.\"\"\"\n",
    "    J = np.argsort(x)\n",
    "    Z = x[J]\n",
    "    N = len(x)\n",
    "    T = np.zeros(N, dtype=float)\n",
    "    i = 0\n",
    "    while i < N:\n",
    "        j = i\n",
    "        while j < N and Z[j] == Z[i]:\n",
    "            j += 1\n",
    "        T[i:j] = 0.5*(i + j - 1) + 1\n",
    "        i = j\n",
    "    T2 = np.empty(N, dtype=float)\n",
    "    T2[J] = T\n",
    "    return T2\n",
    "\n",
    "def _fast_delong(y_true, scores):\n",
    "    \"\"\"Compute DeLong covariance for correlated ROC AUCs.\"\"\"\n",
    "    y_true = np.asarray(y_true)\n",
    "    assert set(np.unique(y_true)) <= {0,1}\n",
    "    n = y_true.size\n",
    "    order = np.argsort(-scores[0, :])\n",
    "    y = y_true[order]\n",
    "    n1 = int(np.sum(y))\n",
    "    n0 = int(n - n1)\n",
    "\n",
    "    aucs = []\n",
    "    v01 = []\n",
    "    v10 = []\n",
    "\n",
    "    for k in range(scores.shape[0]):\n",
    "        s = scores[k, order]\n",
    "        tx = _compute_midrank(s)\n",
    "        ty1 = _compute_midrank(s[y == 1])\n",
    "        ty0 = _compute_midrank(-s[y == 0])\n",
    "\n",
    "        auc = (np.sum(tx[y == 1]) - n1*(n1+1)/2) / (n1*n0)\n",
    "        aucs.append(auc)\n",
    "        v01_k = (ty1 - (n1+1)/2) / n0\n",
    "        v10_k = 1 - (ty0 - (n0+1)/2) / n1\n",
    "        v01.append(v01_k)\n",
    "        v10.append(v10_k)\n",
    "\n",
    "    aucs = np.array(aucs, dtype=float)\n",
    "    v01 = np.array(v01, dtype=float)\n",
    "    v10 = np.array(v10, dtype=float)\n",
    "\n",
    "    s01 = np.cov(v01)\n",
    "    s10 = np.cov(v10)\n",
    "    auc_cov = s01 / n0 + s10 / n1\n",
    "    return aucs, auc_cov\n",
    "\n",
    "def delong_test(y_true, score1, score2):\n",
    "    \"\"\"\n",
    "    DeLong test for correlated ROC AUCs (two models on the same test set).\n",
    "    Returns: auc1, auc2, delta, var, z, p\n",
    "    \"\"\"\n",
    "    s = np.vstack([np.asarray(score1), np.asarray(score2)])\n",
    "    aucs, auc_cov = _fast_delong(np.asarray(y_true), s)\n",
    "    delta = float(aucs[0] - aucs[1])\n",
    "    var = float(auc_cov[0,0] + auc_cov[1,1] - 2*auc_cov[0,1])\n",
    "    z = delta / sqrt(var) if var > 0 else 0.0\n",
    "    p = 2 * (1 - norm.cdf(abs(z)))\n",
    "    return float(aucs[0]), float(aucs[1]), delta, var, float(z), float(p)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4a22a8e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VARITY vs MVP: ΔAUC=0.0008, z=0.009, p=0.993\n",
      "VARITY vs MutScore: ΔAUC=0.0039, z=0.070, p=0.944\n",
      "MVP vs MutScore: ΔAUC=0.0032, z=0.040, p=0.968\n"
     ]
    }
   ],
   "source": [
    "pairs = [\n",
    "    (\"VARITY\", score_varity, \"MVP\", score_mvp),\n",
    "    (\"VARITY\", score_varity, \"MutScore\", score_mutscore),\n",
    "    (\"MVP\", score_mvp, \"MutScore\", score_mutscore)\n",
    "]\n",
    "\n",
    "for name1, s1, name2, s2 in pairs:\n",
    "    auc1, auc2, delta, var, z, p = delong_test(y_true, s1, s2)\n",
    "    print(f\"{name1} vs {name2}: ΔAUC={delta:.4f}, z={z:.3f}, p={p:.3f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
