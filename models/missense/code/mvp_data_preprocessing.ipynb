{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9ae7f53c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import dependencies\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5b2da1d",
   "metadata": {},
   "source": [
    "## Construct original training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b92daed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and merge data for training\n",
    "## Modified from original pipeline\n",
    "files = [\n",
    "    '../data/metaSVM_train.anno.rare.HIS.reformat.csv',\n",
    "    '../data/CADD_neg_train.anno.rare.HIS.reformat.csv',\n",
    "    '../data/clinvar_pathogenic_1-4star.rare.HIS.reformat.csv',\n",
    "    '../data/DiscovEHR_missense_sel.rare.HIS.reformat.csv'\n",
    "]\n",
    "\n",
    "df_list = []\n",
    "for f in files:\n",
    "    print(f\"Loading: {f}\")\n",
    "    df = pd.read_csv(f, on_bad_lines='skip')\n",
    "    df_list.append(df)\n",
    "\n",
    "df_combined = pd.concat(df_list, axis=0, ignore_index=True)\n",
    "\n",
    "print(f\"Shape of combined dataset: {df_combined.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8e2890e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data cleansing and deduplication\n",
    "## Deduplication\n",
    "df_combined = df_combined.drop_duplicates(subset='var_id', keep='first')\n",
    "\n",
    "## Set positive and negative samples\n",
    "pos = df_combined[df_combined.target == 1]\n",
    "neg = df_combined[df_combined.target == 0]\n",
    "\n",
    "## Remove conflicts\n",
    "var_pos = set(pos.var_id)\n",
    "var_neg = set(neg.var_id)\n",
    "pos = pos[~pos.var_id.isin(var_neg)]\n",
    "neg = neg[~neg.var_id.isin(var_pos)]\n",
    "\n",
    "## Merge positive and negative samples\n",
    "df_clean = pd.concat([pos, neg], axis=0, ignore_index=True)\n",
    "\n",
    "print(f\"Shape after cleansing: {df_clean.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3088ef33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature selection\n",
    "exclude_cols = {'var_id', 'aaref', 'aaalt', 'target', 'Ensembl_transcriptid',\n",
    "                'ref', 'alt', 'category',\n",
    "                'source', 'INFO', 'disease', 'genename',\n",
    "                '#chr', 'pos(1-based)', 'hg19_chr', 'hg19_pos(1-based)',\n",
    "                'CADD_phred', '1000Gp3_AF', 'ExAC_AF', 'gnomad',\n",
    "                'RVIS', 'mis_badness', 'MPC', 'REVEL', 'domino'}\n",
    "\n",
    "## Keep the chosen columns\n",
    "feature_cols = [col for col in df_clean.columns if col not in exclude_cols]\n",
    "\n",
    "print(f\"Number of features used for training: {len(feature_cols)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b45a210",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Impute NaN\n",
    "protein_complex_scores = ['complex_CORUM', 'preppi_counts', 'BioPlex'] # Missing values will be assigned 0\n",
    "\n",
    "X_filled = df_clean[feature_cols].copy()\n",
    "\n",
    "for col in X_filled.columns:\n",
    "    if col in protein_complex_scores:\n",
    "        X_filled[col] = pd.to_numeric(X_filled[col], errors='coerce').fillna(0.0)\n",
    "    else:\n",
    "        X_filled[col] = pd.to_numeric(X_filled[col], errors='coerce').fillna(-1.0)\n",
    "\n",
    "X = X_filled.values\n",
    "X = np.nan_to_num(X, nan=0.0)\n",
    "\n",
    "# Check condition of X\n",
    "print(\"Any NaN:\", np.isnan(X).any())\n",
    "print(\"Any Inf:\", np.isinf(X).any())\n",
    "print(\"Shape:\", X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "200cf745",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reorganize DataFrame\n",
    "df_final = pd.DataFrame(X, columns=feature_cols)\n",
    "df_final['target'] = df_clean['target'].values\n",
    "\n",
    "# Save\n",
    "df_final.to_csv('../data/mvp_input_data_cleaned.HIS.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9ebaf51",
   "metadata": {},
   "source": [
    "## Prepare benchmark dataset for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4359dbb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7a7a6415",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load benchmark dataset for training\n",
    "df_training = pd.read_csv('../../../data/training_set.csv')\n",
    "df_training = df_training.rename(columns={'label': 'target'}) # rename to match training pipeline\n",
    "df_training.to_csv('../data/training_set_with_target.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8cf84d90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features used for training (benchmark): 42\n"
     ]
    }
   ],
   "source": [
    "# Select features for training\n",
    "exclude_cols_training = {\n",
    "    'Uploaded_variation', 'level_1', 'Location', 'Allele', 'Gene',\n",
    "    'Feature', 'Feature_type', 'Consequence',\n",
    "    'cDNA_position', 'CDS_position', 'Protein_position', 'Amino_acids',\n",
    "    'Codons', 'Existing_variation', 'IMPACT', 'DISTANCE',\n",
    "    'STRAND', 'FLAGS', 'ClinicalSignificance', 'target', 'MVP_score', 'CANONICAL'\n",
    "}\n",
    "\n",
    "feature_cols_training = [col for col in df_training.columns if col not in exclude_cols_training]\n",
    "print(f\"Number of features used for training (benchmark): {len(feature_cols_training)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a0dad998",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalization\n",
    "X_training = df_training[feature_cols_training].copy()\n",
    "scaler = MinMaxScaler()\n",
    "X_training_scaled = scaler.fit_transform(X_training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "306f0bd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalized benchmark data saved to: training_set_scaled.csv\n"
     ]
    }
   ],
   "source": [
    "# Reconstruct DataFrame\n",
    "X_scaled_df = pd.DataFrame(X_training_scaled, columns=feature_cols_training)\n",
    "X_scaled_df['target'] = df_training['target'].values\n",
    "\n",
    "# Save to file\n",
    "X_scaled_df.to_csv(\"../data/training_set_scaled.csv\", index=False)\n",
    "print(\"Normalized benchmark data saved to: training_set_scaled.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85a4aa72",
   "metadata": {},
   "source": [
    "## Prepare benchmark dataset for test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "570ca3e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load benchmark dataset for test\n",
    "df_test = pd.read_csv('../../../data/test_set.csv')\n",
    "df_test = df_test.rename(columns={'label': 'target'}) # rename to match the pipeline\n",
    "df_test.to_csv('../data/test_set_with_target.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ce5ae046",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features used for test (benchmark): 42\n"
     ]
    }
   ],
   "source": [
    "# Select features for test\n",
    "exclude_cols_test = {\n",
    "    'Uploaded_variation', 'level_1', 'Location', 'Allele', 'Gene',\n",
    "    'Feature', 'Feature_type', 'Consequence',\n",
    "    'cDNA_position', 'CDS_position', 'Protein_position', 'Amino_acids',\n",
    "    'Codons', 'Existing_variation', 'IMPACT', 'DISTANCE',\n",
    "    'STRAND', 'FLAGS', 'ClinicalSignificance', 'target', 'MVP_score', 'CANONICAL'\n",
    "}\n",
    "\n",
    "feature_cols_test = [col for col in df_test.columns if col not in exclude_cols_test]\n",
    "print(f\"Number of features used for test (benchmark): {len(feature_cols_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4fa43853",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalization\n",
    "X_test = df_test[feature_cols_test].copy()\n",
    "scaler = MinMaxScaler()\n",
    "X_test_scaled = scaler.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "caeda138",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalized benchmark data saved to: test_set_scaled.csv\n"
     ]
    }
   ],
   "source": [
    "# Reconstruct DataFrame\n",
    "X_scaled_df = pd.DataFrame(X_test_scaled, columns=feature_cols_test)\n",
    "X_scaled_df['target'] = df_test['target'].values\n",
    "\n",
    "# Save to file\n",
    "X_scaled_df.to_csv(\"../data/test_set_scaled.csv\", index=False)\n",
    "print(\"Normalized benchmark data saved to: test_set_scaled.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mvp_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
